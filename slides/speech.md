# Outline
Today I am to explain you why software security is so important. Language-based security, in particular, may be used for ensuring different properties, both at compile or run time. I am going to give you three examples of them. Although I am not explaining you any implementation detail, I am talking about how they might be simply coded in a functional language, like Haskell.

# Introduction
So, let's start with a question! Why should we care about software security? Well, basically because *everything* is based on software. The bad news is that any compromise to integrity, authentication and availability makes a software unsecure. And what's worse, software cannot be fully tested. It is normally so complex that it is almost impossible, infeasible.
Sometimes, however, it is useful proving mathematically that a software meets some properties. Language-based security aims to do that. Using advanced type systems allows us to rule out leaky programs without even executing them. Entire languages have been built from scratch, but learning or migrating a new language is often annoying. Further, normally those properties are about just a few variables or small parts of the whole software. That's exactly where lightweight libraries come into play. This presentation, and the paper, is about a small Haskell-based security library enforcing three properties.

# Unsecure
The first is about something which has actually been around for years: input validation. I think we are even not able to write a number representing how many bugs have came out due to a lack in input validation. The **Unsecure** module serves this purpose. Basically it encapsulates an unvalidated value and constraints it with some validation functions. Every function is supposed to raise a specific instance of a user-defined error type. 
Consider this function. The string coming from the user is checked for ensuring that's a natural number. This error type is supposed to contain different constructors representing different possible wrong situations. We cannot simply use the value without extracting it, and, for extracting it, we must validate it against these functions. The validation is obviously done at run-time, but we cannot use an Unsecure instance where a Int, String, or whatever is expected.

# SecureFlow
All right, so far so good. Here I am to talk about a fundamental information security principle: non-inference. Non-inference is basically a property specifying the absence of information flows from secret to public data. The way in which is here implemented is based on a security lattice, a mathematical structure where every subject or object is labeled with a security level. Subjects are allowed to access to objects iff their security level is greater, or equal, to the objects one. Since subjects may have different security levels at different times, they have to prove their current level with a ticket. The lattice, as well as the ticketing system, must be instantiated by a trusted programmer. 
However, there's a trouble in paradise. Very often applications need to perform operations on secret data. They also need to *leak* information. That's where declassification comes into play. It is a controlled way of leaking information. Basically two approaches may be used in this context. The first is hard-coding those policies into a language, but it is extremely complex. The other way is to define a declassification combinator and, according to the functional paradigm, build more and more complicated policies using those which have been previously defined.
Consider the following example. There is a private credential database. How can we implement a login function? The database is unreadable, and every attempt to access it with a public ticket will raise a compilation error. Anyway, if we define a declassification function, we shall be able to access to that just for the stated purpose. I mean, the login. Those function must be carefully defined, since they are actually, although controlled, way of leaking information.

# SecureComputation
And we arrive to the third, the last, module. SecureComputation. This is based on the taint analysis idea. However, taint analysis is something dynamic, and it takes place at run-time. This is quite restrictive. What if we would be able to enforce computation only on pure values? This is the aim of SecureComputation. Basically operations on secure, sensitive, data should be allowed only if the values are trusted and pure. Consider the following example. Here a string is read and marked as tainted. Further, there's a function requiring a pure value for computing something. If a tainted value is used as a parameter for this function, a compilation error is raised. In this manner the compiler is checking for us that no tainted value is used as a parameter in sensitive functions. 

# Conclusions
All right, that sounds great. These simple modules, based on widespread functional programming concepts, allow us to ensure some fundamental security properties. Further, they may be used for small portions on the entire software, on demand. But again, there's a trouble in paradise. Unfortunately, new IO functions must be defined to introduce two of these modules in the application code. Moreover, the type constraints required for the implementation of both Unsecure or SecureComputation, prevent them to be defined as standard monad instances. And last, there should be some kind of relation between Unsecure and SecureComputation, for allowing unvalidated values to be used as tainted values.